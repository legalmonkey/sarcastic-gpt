{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c20a29-d78a-42ba-825a-20d43afb3986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 1, 'NVIDIA GeForce RTX 3050 6GB Laptop GPU')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (device)\n",
    "block_size=256\n",
    "batch_size=64\n",
    "\n",
    "max_iters= 50000\n",
    "#eval_interval=2500\n",
    "learning_rate= 1e-4\n",
    "eval_iters=100\n",
    "eval_interval=500\n",
    "n_embd=512\n",
    "n_head=8\n",
    "n_layer=6\n",
    "dropout = 0.1\n",
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38793d06-f761-4b4f-ba6c-e214c6f5fece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using byte-level vocabulary of size 256\n"
     ]
    }
   ],
   "source": [
    "# BYTE-LEVEL VOCAB (FIXED)\n",
    "vocab_size = 256\n",
    "print(\"Using byte-level vocabulary of size\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2b088b-33fe-4708-a8ec-b021aee564ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BYTE-LEVEL ENCODE / DECODE (FIXED)\n",
    "\n",
    "def encode(text: str):\n",
    "    # UTF-8 bytes → integers [0,255]\n",
    "    return list(text.encode(\"utf-8\"))\n",
    "\n",
    "def decode(tokens):\n",
    "    # integers [0,255] → UTF-8 text\n",
    "    return bytes(tokens).decode(\"utf-8\", errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6c6ba4-bbc8-4205-8054-c89a399a1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open(\"output_train.txt\", \"rb\")\n",
    "val_file   = open(\"output_val.txt\", \"rb\")\n",
    "\n",
    "train_mm = mmap.mmap(train_file.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "val_mm   = mmap.mmap(val_file.fileno(),   0, access=mmap.ACCESS_READ)\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    mm = train_mm if split == \"train\" else val_mm\n",
    "    file_size = len(mm)\n",
    "\n",
    "    ix = torch.randint(\n",
    "        0,\n",
    "        file_size - block_size - 1,\n",
    "        (batch_size,)\n",
    "    )\n",
    "\n",
    "    x = torch.stack([\n",
    "        torch.frombuffer(\n",
    "            mm[i : i + block_size],\n",
    "            dtype=torch.uint8\n",
    "        ).long()\n",
    "        for i in ix\n",
    "    ])\n",
    "\n",
    "    y = torch.stack([\n",
    "        torch.frombuffer(\n",
    "            mm[i + 1 : i + block_size + 1],\n",
    "            dtype=torch.uint8\n",
    "        ).long().clamp(0, vocab_size - 1)\n",
    "        for i in ix\n",
    "    ])\n",
    "\n",
    "\n",
    "    return x.to(device), y.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be549bb-c696-4853-a3b8-9f80a3d85724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model parameters..\n"
     ]
    }
   ],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(256, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        #logits=self.token_embedding_table(index)\n",
    "        B,T= index.shape\n",
    "        \n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "print(\"Loading model parameters..\")\n",
    "#with open('model-01.pkl','rb') as f:\n",
    " #   model = pickle.load(f)\n",
    "#print('loaded successfully!')\n",
    "\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92973673-bfe2-438b-a227-b995eb399414",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce405dc7-c7b5-4177-a041-3eceb9cccb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ritvik Bhat\\AppData\\Local\\Temp\\ipykernel_21572\\3674558382.py:19: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:1587.)\n",
      "  torch.frombuffer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 5.673, val loss: 5.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ritvik Bhat\\AppData\\Local\\Temp\\ipykernel_21572\\1878896799.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 500, train loss: 2.259, val loss: 2.264\n",
      "step: 1000, train loss: 2.240, val loss: 2.251\n",
      "step: 1500, train loss: 2.239, val loss: 2.216\n",
      "step: 2000, train loss: 2.214, val loss: 2.210\n",
      "step: 2500, train loss: 2.198, val loss: 2.194\n",
      "step: 3000, train loss: 2.178, val loss: 2.186\n",
      "step: 3500, train loss: 2.147, val loss: 2.149\n",
      "step: 4000, train loss: 2.087, val loss: 2.079\n",
      "step: 4500, train loss: 2.047, val loss: 2.040\n",
      "step: 5000, train loss: 2.016, val loss: 2.006\n",
      "step: 5500, train loss: 1.987, val loss: 1.987\n",
      "step: 6000, train loss: 1.965, val loss: 1.953\n",
      "step: 6500, train loss: 1.949, val loss: 1.952\n",
      "step: 7000, train loss: 1.937, val loss: 1.934\n",
      "step: 7500, train loss: 1.950, val loss: 1.916\n",
      "step: 8000, train loss: 1.917, val loss: 1.926\n",
      "step: 8500, train loss: 1.931, val loss: 1.912\n",
      "step: 9000, train loss: 1.916, val loss: 1.920\n",
      "step: 9500, train loss: 1.922, val loss: 1.925\n",
      "step: 10000, train loss: 1.903, val loss: 1.903\n",
      "step: 10500, train loss: 1.884, val loss: 1.909\n",
      "step: 11000, train loss: 1.903, val loss: 1.895\n",
      "step: 11500, train loss: 1.887, val loss: 1.895\n",
      "step: 12000, train loss: 1.852, val loss: 1.876\n",
      "step: 12500, train loss: 1.866, val loss: 1.871\n",
      "step: 13000, train loss: 1.858, val loss: 1.865\n",
      "step: 13500, train loss: 1.847, val loss: 1.846\n",
      "step: 14000, train loss: 1.868, val loss: 1.845\n",
      "step: 14500, train loss: 1.850, val loss: 1.866\n",
      "step: 15000, train loss: 1.845, val loss: 1.840\n",
      "step: 15500, train loss: 1.849, val loss: 1.831\n",
      "step: 16000, train loss: 1.846, val loss: 1.835\n",
      "step: 16500, train loss: 1.847, val loss: 1.833\n",
      "step: 17000, train loss: 1.832, val loss: 1.825\n",
      "step: 17500, train loss: 1.814, val loss: 1.821\n",
      "step: 18000, train loss: 1.823, val loss: 1.822\n",
      "step: 18500, train loss: 1.809, val loss: 1.820\n",
      "step: 19000, train loss: 1.807, val loss: 1.811\n",
      "step: 19500, train loss: 1.805, val loss: 1.803\n",
      "step: 20000, train loss: 1.808, val loss: 1.807\n",
      "step: 20500, train loss: 1.795, val loss: 1.804\n",
      "step: 21000, train loss: 1.798, val loss: 1.805\n",
      "step: 21500, train loss: 1.784, val loss: 1.800\n",
      "step: 22000, train loss: 1.802, val loss: 1.798\n",
      "step: 22500, train loss: 1.777, val loss: 1.797\n",
      "step: 23000, train loss: 1.797, val loss: 1.794\n",
      "step: 23500, train loss: 1.802, val loss: 1.793\n",
      "step: 24000, train loss: 1.792, val loss: 1.781\n",
      "step: 24500, train loss: 1.774, val loss: 1.789\n",
      "step: 25000, train loss: 1.800, val loss: 1.770\n",
      "step: 25500, train loss: 1.774, val loss: 1.777\n",
      "step: 26000, train loss: 1.772, val loss: 1.770\n",
      "step: 26500, train loss: 1.770, val loss: 1.771\n",
      "step: 27000, train loss: 1.774, val loss: 1.762\n",
      "step: 27500, train loss: 1.768, val loss: 1.766\n",
      "step: 28000, train loss: 1.770, val loss: 1.778\n",
      "step: 28500, train loss: 1.766, val loss: 1.754\n",
      "step: 29000, train loss: 1.761, val loss: 1.762\n",
      "step: 29500, train loss: 1.772, val loss: 1.773\n",
      "step: 30000, train loss: 1.773, val loss: 1.756\n",
      "step: 30500, train loss: 1.760, val loss: 1.750\n",
      "step: 31000, train loss: 1.745, val loss: 1.760\n",
      "step: 31500, train loss: 1.770, val loss: 1.740\n",
      "step: 32000, train loss: 1.749, val loss: 1.760\n",
      "step: 32500, train loss: 1.767, val loss: 1.748\n",
      "step: 33000, train loss: 1.753, val loss: 1.742\n",
      "step: 33500, train loss: 1.755, val loss: 1.760\n",
      "step: 34000, train loss: 1.758, val loss: 1.749\n",
      "step: 34500, train loss: 1.731, val loss: 1.746\n",
      "step: 35000, train loss: 1.755, val loss: 1.750\n",
      "step: 35500, train loss: 1.760, val loss: 1.752\n",
      "step: 36000, train loss: 1.756, val loss: 1.745\n",
      "step: 36500, train loss: 1.743, val loss: 1.747\n",
      "step: 37000, train loss: 1.757, val loss: 1.743\n",
      "step: 37500, train loss: 1.739, val loss: 1.757\n",
      "step: 38000, train loss: 1.746, val loss: 1.746\n",
      "step: 38500, train loss: 1.746, val loss: 1.744\n",
      "step: 39000, train loss: 1.763, val loss: 1.736\n",
      "step: 39500, train loss: 1.734, val loss: 1.732\n",
      "step: 40000, train loss: 1.729, val loss: 1.746\n",
      "step: 40500, train loss: 1.765, val loss: 1.738\n",
      "step: 41000, train loss: 1.743, val loss: 1.734\n",
      "step: 41500, train loss: 1.749, val loss: 1.743\n",
      "step: 42000, train loss: 1.735, val loss: 1.744\n",
      "step: 42500, train loss: 1.740, val loss: 1.745\n",
      "step: 43000, train loss: 1.744, val loss: 1.741\n",
      "step: 43500, train loss: 1.748, val loss: 1.737\n",
      "step: 44000, train loss: 1.735, val loss: 1.738\n",
      "step: 44500, train loss: 1.728, val loss: 1.748\n",
      "step: 45000, train loss: 1.733, val loss: 1.735\n",
      "step: 45500, train loss: 1.748, val loss: 1.752\n",
      "step: 46000, train loss: 1.736, val loss: 1.738\n",
      "step: 46500, train loss: 1.731, val loss: 1.745\n",
      "step: 47000, train loss: 1.748, val loss: 1.754\n",
      "step: 47500, train loss: 1.747, val loss: 1.740\n",
      "step: 48000, train loss: 1.737, val loss: 1.748\n",
      "step: 48500, train loss: 1.746, val loss: 1.746\n",
      "step: 49000, train loss: 1.737, val loss: 1.742\n",
      "step: 49500, train loss: 1.751, val loss: 1.748\n",
      "1.8022539615631104\n"
     ]
    }
   ],
   "source": [
    "#pytorch optimizer\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,                \n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.1\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=max_iters          \n",
    ")\n",
    "\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device == \"cuda\"))\n",
    "\n",
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(\n",
    "            f\"step: {iter}, \"\n",
    "            f\"train loss: {losses['train']:.3f}, \"\n",
    "            f\"val loss: {losses['val']:.3f}\"\n",
    "        )\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # AMP forward + loss\n",
    "    with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "\n",
    "    # stabilize gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # optimizer step\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04834e5e-590d-43a3-9e37-efd705f2e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "with open('model-01-v2.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e6901d3-217d-4c17-83e2-78f2118fcb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000991954e90fe0f38ct\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u000000000000\u00000000000957\u0000007000000000\u0000000000001\u0000 IChes Oar Exubar Polic (DeabouPs by 17, xpicerdctations and sturalics nout agrourater the clicasor chaps in 296t aloan narery Freay prentorica and numinuttion Shative ain, and vouading, may the seely machions Sireater aplopos. The Irdme as Chatirnic-pecrcons,” Un: Chustial #\n",
      "\n",
      "the sment to I partsolians that not, Moding inty modising \n"
     ]
    }
   ],
   "source": [
    "context =  torch.zeros((1,1),dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e840c-fe8e-4f2f-b29c-71143376c58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
