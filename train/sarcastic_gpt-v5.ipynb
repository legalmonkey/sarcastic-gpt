{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c20a29-d78a-42ba-825a-20d43afb3986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (device)\n",
    "block_size=256\n",
    "batch_size=32\n",
    "\n",
    "max_iters= 40000\n",
    "#eval_interval=2500\n",
    "learning_rate= 5e-4\n",
    "eval_iters=5\n",
    "eval_interval=3000\n",
    "n_embd=512\n",
    "n_head=8\n",
    "n_layer=6\n",
    "dropout = 0.1\n",
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.get_device_name(0)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "# ===== Early stopping config =====\n",
    "EARLY_STOP_PATIENCE = 4        # number of evals with no improvement\n",
    "MIN_LOSS_DELTA = 0.02          # minimum improvement to count\n",
    "TARGET_PPL = 28.0              # stop immediately if reached\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38793d06-f761-4b4f-ba6c-e214c6f5fece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import sentencepiece as spm\\n\\nspm.SentencePieceTrainer.train(\\n    input=\"wiki_clean.txt\",\\n    model_prefix=\"bpe\",\\n    vocab_size=8000,\\n    model_type=\"bpe\",\\n    character_coverage=1.0,\\n    bos_id=-1,\\n    eos_id=-1,\\n    unk_id=0\\n)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"wiki_clean.txt\",\n",
    "    model_prefix=\"bpe\",\n",
    "    vocab_size=8000,\n",
    "    model_type=\"bpe\",\n",
    "    character_coverage=1.0,\n",
    "    bos_id=-1,\n",
    "    eos_id=-1,\n",
    "    unk_id=0\n",
    ")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2b088b-33fe-4708-a8ec-b021aee564ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BPE vocab size: 8000\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"bpe.model\")\n",
    "\n",
    "vocab_size = sp.get_piece_size()\n",
    "print(\"Using BPE vocab size:\", vocab_size)\n",
    "\n",
    "def encode(text: str):\n",
    "    return sp.encode(text, out_type=int)\n",
    "\n",
    "def decode(tokens):\n",
    "    return sp.decode(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9615bf1-17eb-4afb-8dfe-1adb2a65d717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets (one-time cost)...\n"
     ]
    }
   ],
   "source": [
    "def load_tokens(path, chunk_size=100_000):\n",
    "    all_tokens = []\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            all_tokens.extend(encode(chunk))\n",
    "\n",
    "    return torch.tensor(all_tokens, dtype=torch.long)\n",
    "\n",
    "\n",
    "print(\"Tokenizing datasets (one-time cost)...\")\n",
    "#tokens = load_tokens(\"wiki_clean.txt\")\n",
    "tokens = torch.load(\"wiki_tokens.pt\")\n",
    "train_tokens = tokens.to(device)\n",
    "val_tokens   = tokens.to(device)\n",
    "torch.save(tokens, \"wiki_tokens.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6c6ba4-bbc8-4205-8054-c89a399a1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import random\n",
    "\n",
    "with open(\"wiki_clean.txt\", \"rb\") as f:\n",
    "    wiki_mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_tokens if split == \"train\" else val_tokens\n",
    "\n",
    "    # sample starting indices on GPU\n",
    "    ix = torch.randint(\n",
    "        0, data.size(0) - block_size - 1,\n",
    "        (batch_size,),\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # vectorized slicing (NO Python loops)\n",
    "    offsets = torch.arange(block_size, device=device)\n",
    "    x = data[ix[:, None] + offsets]\n",
    "    y = data[ix[:, None] + offsets + 1]\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629f5d43-5356-418e-a89d-0c596ede4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(\n",
    "    prompt: str,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7,\n",
    "    top_k=40\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    # IMPORTANT FIX: force leading space\n",
    "    if not prompt.startswith(\" \"):\n",
    "        prompt = \" \" + prompt\n",
    "\n",
    "    idx = torch.tensor([encode(prompt)], dtype=torch.long).to(device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        logits, _ = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, top_k)\n",
    "            logits[logits < v[:, [-1]]] = -float(\"inf\")\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    text = decode(idx[0].tolist())\n",
    "\n",
    "    # Optional cleanup: strip leading space\n",
    "    return text.lstrip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be549bb-c696-4853-a3b8-9f80a3d85724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer(\n",
    "            'tril',\n",
    "            torch.tril(torch.ones(block_size, block_size)),\n",
    "            persistent=False\n",
    "        )\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, int(4 * n_embd)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        #logits=self.token_embedding_table(index)\n",
    "        B,T= index.shape\n",
    "        \n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos = torch.arange(T, device=index.device)\n",
    "        pos_emb = self.position_embedding_table(pos)\n",
    "\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def sample_logits(logits, temperature=0.8, top_k=40):\n",
    "        logits = logits / temperature\n",
    "        v, ix = torch.topk(logits, top_k)\n",
    "        probs = torch.softmax(v, dim=-1)\n",
    "        return ix[torch.multinomial(probs, 1)]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            index_next = sample_logits(logits)\n",
    "\n",
    "\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def stage1_language_test():\n",
    "    model.eval()\n",
    "\n",
    "    prompts = [\n",
    "        \"The capital city of France is\",\n",
    "        \"The history of science is\",\n",
    "        \"In recent years, machine learning has\",\n",
    "        \"A common misconception about physics is\",\n",
    "        \"Education plays an important role in society because\",\n",
    "    ]\n",
    "\n",
    "    for p in prompts:\n",
    "        out = generate_text(\n",
    "            p,\n",
    "            max_new_tokens=100,\n",
    "            temperature=0.7,   # lower temp = better coherence for Stage-1\n",
    "            top_k=40\n",
    "        )\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PROMPT:\", p)\n",
    "        print(out)\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da94f0c8-22e2-407d-9d5f-38af6c0c49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_perplexity():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for _ in range(eval_iters):\n",
    "        X, Y = get_batch(\"val\")\n",
    "        _, loss = model(X, Y)\n",
    "        losses.append(loss.item())\n",
    "    model.train()\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    return avg_loss, math.exp(avg_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92973673-bfe2-438b-a227-b995eb399414",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842d9260-324f-48b2-b7eb-d59f028cd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "step_times = []\n",
    "LOG_EVERY = 100   # log speed every N steps\n",
    "t_last = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce405dc7-c7b5-4177-a041-3eceb9cccb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[speed] 2.33 steps/s | 0.429 s/step\n",
      "[speed] 2.54 steps/s | 0.394 s/step\n",
      "[speed] 2.54 steps/s | 0.393 s/step\n",
      "[speed] 2.52 steps/s | 0.396 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "step 3000 | val loss 4.164 | ppl 64.3\n",
      "✓ New best model saved\n",
      "[speed] 2.50 steps/s | 0.400 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "step 6000 | val loss 3.809 | ppl 45.1\n",
      "✓ New best model saved\n",
      "[speed] 2.51 steps/s | 0.399 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "step 9000 | val loss 3.620 | ppl 37.3\n",
      "✓ New best model saved\n",
      "[speed] 2.50 steps/s | 0.399 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.390 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.52 steps/s | 0.397 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.55 steps/s | 0.391 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.393 s/step\n",
      "[speed] 2.54 steps/s | 0.394 s/step\n",
      "[speed] 2.50 steps/s | 0.400 s/step\n",
      "[speed] 2.52 steps/s | 0.398 s/step\n",
      "[speed] 2.25 steps/s | 0.444 s/step\n",
      "[speed] 2.52 steps/s | 0.396 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "step 12000 | val loss 3.487 | ppl 32.7\n",
      "✓ New best model saved\n",
      "[speed] 2.50 steps/s | 0.400 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.45 steps/s | 0.408 s/step\n",
      "[speed] 2.54 steps/s | 0.394 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "step 15000 | val loss 3.400 | ppl 30.0\n",
      "✓ New best model saved\n",
      "[speed] 2.51 steps/s | 0.399 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "step 18000 | val loss 3.337 | ppl 28.1\n",
      "✓ New best model saved\n",
      "[speed] 2.51 steps/s | 0.399 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.55 steps/s | 0.392 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "[speed] 2.56 steps/s | 0.391 s/step\n",
      "step 21000 | val loss 3.326 | ppl 27.8\n",
      "No improvement count: 1/4\n",
      "✓ Target perplexity 28.0 reached. Stopping early.\n"
     ]
    }
   ],
   "source": [
    "TEST_EVERY = 500  # how often to test sarcasm\n",
    "best_val_loss = float(\"inf\")\n",
    "no_improve_count = 0\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=max_iters\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device == \"cuda\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # ===== evaluation & early stopping =====\n",
    "    if iter > 0 and iter % eval_interval == 0:\n",
    "        val_loss, ppl = estimate_perplexity()\n",
    "\n",
    "        print(\n",
    "            f\"step {iter} | \"\n",
    "            f\"val loss {val_loss:.3f} | \"\n",
    "            f\"ppl {ppl:.1f}\"\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss - MIN_LOSS_DELTA:\n",
    "            best_val_loss = val_loss\n",
    "            no_improve_count = 0\n",
    "            torch.save(model.state_dict(), \"stage1_best.pt\")\n",
    "            print(\"✓ New best model saved\")\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            print(f\"No improvement count: {no_improve_count}/{EARLY_STOP_PATIENCE}\")\n",
    "\n",
    "        if ppl <= TARGET_PPL:\n",
    "            print(f\"✓ Target perplexity {TARGET_PPL} reached. Stopping early.\")\n",
    "            break\n",
    "\n",
    "        if no_improve_count >= EARLY_STOP_PATIENCE:\n",
    "            print(\"✓ Early stopping triggered (plateau).\")\n",
    "            break\n",
    "\n",
    "    # ===== training step =====\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    with torch.amp.autocast(\"cuda\", enabled=(device == \"cuda\")):\n",
    "        _, loss = model(xb, yb)\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    scheduler.step()\n",
    "\n",
    "    # ===== speed logging =====\n",
    "    if iter % LOG_EVERY == 0 and iter > 0:\n",
    "        torch.cuda.synchronize()\n",
    "        t_now = time.time()\n",
    "        dt = t_now - t_last\n",
    "\n",
    "        steps_per_sec = LOG_EVERY / dt\n",
    "        secs_per_step = dt / LOG_EVERY\n",
    "\n",
    "        print(\n",
    "            f\"[speed] {steps_per_sec:.2f} steps/s | \"\n",
    "            f\"{secs_per_step:.3f} s/step\"\n",
    "        )\n",
    "\n",
    "        t_last = t_now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04834e5e-590d-43a3-9e37-efd705f2e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROMPT: The capital city of France is\n",
      "The capital city of France is Salvadal. References Cities in Salvador Salza is a municipality in the canton of Salvador in Switzerland. It is in the western part of Salvador. References Other websites Official Summer Paralympic Skarvadorg Municipality. References Other websites Rafael Rayettle Salvatos (Bluevalaria) is a\n",
      "\n",
      "================================================================================\n",
      "PROMPT: The history of science is\n",
      "The history of science is an organization of the Natural History of Historic and Armenia. It was also called the \"Repal of the Middle East\" by Francisco. The newspaper was written by Middlesex and the Napalism in the 19th century. The name was written by Alexander Church. The book was published in 1847 by Frank Lua Melly Gustafs. The book\n",
      "\n",
      "================================================================================\n",
      "PROMPT: In recent years, machine learning has\n",
      "In recent years, machine learning has a long telen place. When a person may be shift when the length of the ground and green dark is still away. A few weapon is used to make a baller. It is used to make a ground, because it may be used in a nutumway. A next green fish is used for a burrow branch, bracking, or bracks. A b\n",
      "\n",
      "================================================================================\n",
      "PROMPT: A common misconception about physics is\n",
      "A common misconception about physics is a medical senior. Scientists believe that theology was a religious senator, and healthy, for example, his wife, Selson My Sell, who finds him away from the Soviet Union. His friends were: Veniol, A Sovietsky, Jesus, Selena, and Selena. At the age of 74. The must be\n",
      "\n",
      "================================================================================\n",
      "PROMPT: Education plays an important role in society because\n",
      "Education plays an important role in society because of its own personal life, is a political party, a public healthy. He is not a magazine. He was active in the National Party. He is the current Senate in the state of Canada, the United States, and the United States House of Representatives from 2007 to 2009. He served as the Senate from 2005 to 2004. In 2012, he was Chairman of the Representatives of the Representat\n"
     ]
    }
   ],
   "source": [
    "stage1_language_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e840c-fe8e-4f2f-b29c-71143376c58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16705def-5af8-445f-a6ec-2aa1c7fb1428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 -> ' ⁇ '\n",
      " 1 -> 't'\n",
      " 2 -> 'he'\n",
      " 3 -> 'an'\n",
      " 4 -> 'in'\n",
      " 5 -> 'er'\n",
      " 6 -> 'on'\n",
      " 7 -> 'a'\n",
      " 8 -> 'the'\n",
      " 9 -> 'es'\n",
      "10 -> 'or'\n",
      "11 -> 'is'\n",
      "12 -> 'en'\n",
      "13 -> 'ar'\n",
      "14 -> 'o'\n",
      "15 -> 'at'\n",
      "16 -> 'w'\n",
      "17 -> 'ed'\n",
      "18 -> 's'\n",
      "19 -> 'it'\n",
      "20 -> 'al'\n",
      "21 -> 'of'\n",
      "22 -> 'in'\n",
      "23 -> 'c'\n",
      "24 -> 'ic'\n",
      "25 -> 'and'\n",
      "26 -> 'f'\n",
      "27 -> 're'\n",
      "28 -> 'b'\n",
      "29 -> 'as'\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first 30 token IDs\n",
    "for i in range(30):\n",
    "    piece = decode([i])\n",
    "    print(f\"{i:2d} -> {repr(piece)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56c5b84b-4012-4dc9-ac8b-619f21cb7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text_english_test(\n",
    "    prompt: str,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.6,\n",
    "    top_k=40\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    if not prompt.startswith(\" \"):\n",
    "        prompt = \" \" + prompt\n",
    "\n",
    "    idx = torch.tensor([encode(prompt)], dtype=torch.long).to(device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        logits, _ = model(idx_cond)\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "\n",
    "        # SOFT English bias: penalize non-ASCII-heavy tokens\n",
    "        for i in range(logits.size(-1)):\n",
    "            piece = decode([i])\n",
    "            if any(ord(c) > 127 for c in piece):\n",
    "                logits[:, i] -= 5.0   # strong penalty\n",
    "\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, top_k)\n",
    "            logits[logits < v[:, [-1]]] = -float(\"inf\")\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return decode(idx[0].tolist()).lstrip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a98430-0239-4211-815f-375e4bdc0b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT: The capital city of France is\n",
      "The capital city of France is Rio de la Loire-Roire, in the province of France. Communes in Loire-Atlantique Haut-Ruy is a commune of 5,59 people (1999). It is found in the region Pays de la Loire in the Saine department in the northwest of France. Communes in Sardinia Aux is a commune. It is found in the region Pays de la Loire in the Saine department in the northwest of France. Communes in Somme Saint-\n",
      "\n",
      "PROMPT: The history of science is\n",
      "The history of science is the first book written by the book of the book of the book. The book is the book of the book of the book, the book is a book written by the book by the book of the book of the book of the book. It is written by the book of the book, The book of the book by Robert. The book was written by Mattel. The book is published in the book by the book of the book, The book of the book by R. The books of the books of books, in the book, and the book of the books. The book of\n",
      "\n",
      "PROMPT: In recent years, machine learning has\n",
      "In recent years, machine learning has been critically liked by the ellips of the utility of the idea that had been creatored. References Diseases of Diseases Disease Disney disease Disney disease deaths Disney Disney animated movies Disney animated movies Disney animated movies Disney animated movies Disney animated movies Disney animated movies Disney animated movies Disney movies Disney animated movies Disney animated movies The Disney anim\n"
     ]
    }
   ],
   "source": [
    "for p in [\n",
    "    \"The capital city of France is\",\n",
    "    \"The history of science is\",\n",
    "    \"In recent years, machine learning has\",\n",
    "]:\n",
    "    print(\"\\nPROMPT:\", p)\n",
    "    print(generate_text_english_test(p, 120))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355bac6-8c78-4aad-9750-a4fdce0b20e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
